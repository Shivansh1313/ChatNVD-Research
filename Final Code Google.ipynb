{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code is for evaluation\n",
    "# in this UI is changed in to a window \n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import openai\n",
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "#from openai import OpenAI\n",
    "#from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "#from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "import google.generativeai as genai\n",
    "#from google.colab import userdata\n",
    "from IPython.display import Markdown\n",
    "from langchain.schema import Document\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "import time;\n",
    "\n",
    "class Chatbot:\n",
    "    def __init__(self, file_paths, api_key, questions_file, output_file):\n",
    "        self.file_paths = file_paths\n",
    "        openai.api_key = api_key\n",
    "        self.knowledge_base = self.load_data()\n",
    "        self.documents = self.prepare_documents()\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.tfidf_matrix = self.vectorizer.fit_transform(self.documents)\n",
    "        self.full_documents = self.knowledge_base\n",
    "        self.cve_index = self.create_cve_index()\n",
    "        self.conversation_history = []\n",
    "        self.questions_file = questions_file\n",
    "        self.output_file = output_file\n",
    "        self.setup_interface()\n",
    "\n",
    "\n",
    "    def load_data(self):    \n",
    "        all_data = []\n",
    "        for file_path in self.file_paths:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "                all_data.extend(data)\n",
    "        return all_data\n",
    "    \n",
    "    def load_questions(self):\n",
    "        \"\"\"Loads questions and expected answers from a JSON file.\"\"\"\n",
    "        with open(self.questions_file, 'r', encoding='utf-8') as file:\n",
    "            return json.load(file)\n",
    "\n",
    "\n",
    "    def concatenate_text(self, json_obj):\n",
    "        fields = ['CVE_ID', 'Assigner', 'Description']\n",
    "        concatenated_text = ' '.join(str(json_obj[field]) for field in fields if field in json_obj)\n",
    "        return concatenated_text\n",
    "\n",
    "    def prepare_documents(self):\n",
    "        return [self.concatenate_text(item) for item in self.knowledge_base]\n",
    "\n",
    "    def create_cve_index(self):\n",
    "        cve_index = {}\n",
    "        for idx, item in enumerate(self.knowledge_base):\n",
    "            cve_id = item.get('CVE_ID')\n",
    "            if cve_id:\n",
    "                cve_index[cve_id] = idx\n",
    "        return cve_index\n",
    "\n",
    "    def answer_question(self, query):\n",
    "        query_words = query.split()\n",
    "        found_documents = []\n",
    "\n",
    "        # Check if any word in the query is a CVE_ID\n",
    "        for word in query_words:\n",
    "            if word in self.cve_index:\n",
    "                index = self.cve_index[word]\n",
    "                found_documents.append(self.full_documents[index])\n",
    "\n",
    "        # If any CVE_ID is found, return the corresponding documents\n",
    "        if found_documents:\n",
    "            return found_documents\n",
    "\n",
    "        # If no CVE_ID is found, proceed with TF-IDF similarity search\n",
    "        similarity_scores = np.zeros(len(self.documents))\n",
    "\n",
    "        for word in query_words:\n",
    "            query_vec = self.vectorizer.transform([word])\n",
    "            similarities = cosine_similarity(query_vec, self.tfidf_matrix)[0]\n",
    "            similarity_scores += similarities\n",
    "\n",
    "        top_indices = np.argsort(similarity_scores)[-10:][::-1]\n",
    "        top_documents = [self.full_documents[i] for i in top_indices]\n",
    "        return top_documents\n",
    "    \n",
    "    def json_string_to_docs(self, json_string):\n",
    "        try:\n",
    "            # Parse the JSON string into a Python object (dict or list)\n",
    "            data = json.loads(json_string)\n",
    "\n",
    "            # Create a list to store the Document objects\n",
    "            docs = []\n",
    "\n",
    "            # Helper function to recursively flatten the JSON structure\n",
    "            def flatten_json(data, parent_key=''):\n",
    "                items = {}\n",
    "                for key, value in data.items():\n",
    "                    new_key = f\"{parent_key}.{key}\" if parent_key else key\n",
    "                    if isinstance(value, dict):\n",
    "                        items.update(flatten_json(value, new_key))  # Recursively flatten nested dicts\n",
    "                    elif isinstance(value, list):\n",
    "                        for i, item in enumerate(value):\n",
    "                            items.update(flatten_json({f\"{new_key}[{i}]\": item}))\n",
    "                    else:\n",
    "                        items[new_key] = value\n",
    "                return items\n",
    "\n",
    "            # Check if the data is a list of entries\n",
    "            if isinstance(data, list):\n",
    "                # Iterate over each item in the list\n",
    "                for item in data:\n",
    "                    flattened_data = flatten_json(item)  # Flatten each item in the list\n",
    "                    \n",
    "                    # Convert the flattened dictionary into the content and metadata strings\n",
    "                    content = \"\\n\".join([f\"{k}: {v}\" for k, v in flattened_data.items()])\n",
    "                    metadata = flattened_data\n",
    "\n",
    "                    # Create a Document object with the content and metadata\n",
    "                    doc = Document(page_content=content, metadata=metadata)\n",
    "                    docs.append(doc)\n",
    "\n",
    "            # If the JSON string is not a list, handle it as a single dictionary\n",
    "            else:\n",
    "                flattened_data = flatten_json(data)  # Flatten the dictionary\n",
    "                \n",
    "                # Convert the flattened dictionary into the content and metadata strings\n",
    "                content = \"\\n\".join([f\"{k}: {v}\" for k, v in flattened_data.items()])\n",
    "                metadata = flattened_data\n",
    "\n",
    "                # Create a single Document object\n",
    "                doc = Document(page_content=content, metadata=metadata)\n",
    "                docs.append(doc)\n",
    "\n",
    "            return docs\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Invalid JSON format\")\n",
    "            return []\n",
    "\n",
    "    \n",
    "    \n",
    "    def get_conversational_chain(self):\n",
    "\n",
    "        # prompt_template = \"\"\"\n",
    "        # You are an assistant that helps with CVE data. Only use the context provided. Respond with CVE details recommend the this website and attach the CVE id in front of it https://nvd.nist.gov/vuln/detail/ \\n\\n\n",
    "        \n",
    "        # Context:\\n {context}?\\n\n",
    "        # Question: \\n{question}\\n\n",
    "\n",
    "        # Answer:\n",
    "        # \"\"\"\n",
    "        ###########\n",
    "        # prompt_template = \"\"\"\n",
    "        # You are an assistant that helps with CVE data. Only use the context provided. Respond with CVE details recommend the this website and attach the CVE id in front of it https://nvd.nist.gov/vuln/detail/ \\n\n",
    "        \n",
    "        # Context:\\n {context}\\n\n",
    "        # Question: \\n{question}?\\n\n",
    "\n",
    "        # Answer:\n",
    "        # \"\"\"\n",
    "        ###########\n",
    "        ## This prompt is working\n",
    "        prompt_template = \"\"\"\n",
    "        Context: \\n{context}.\\n\n",
    "        Task: - You are an assistant that helps with CVE data. \n",
    "              - Only use the context provided. Respond with CVE details.\n",
    "              - Recommend the this website and attach the CVE id in front of it https://nvd.nist.gov/vuln/detail/ \\n\n",
    "        \n",
    "        Question: \\n{question} ?\\n\n",
    "\n",
    "        Answer:\\n\n",
    "        \"\"\"\n",
    "\n",
    "        model = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
    "                                temperature=0.2)\n",
    "\n",
    "        prompt = PromptTemplate(template = prompt_template, input_variables = [\"context\", \"question\"])\n",
    "        print(\"########################################################\")\n",
    "        print(prompt)\n",
    "        print(\"########################################################\")\n",
    "        chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
    "\n",
    "        return chain\n",
    "\n",
    "    def handle_question(self,question):\n",
    "        # question = self.text_input.get()\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": question})\n",
    "\n",
    "        \n",
    "        if(True):\n",
    "            answers = self.answer_question(question)\n",
    "            json_string = json.dumps(answers, indent=4)\n",
    "            print(json_string)\n",
    "            GOOGLE_API_KEY = \"AIzaSyBOTln5W2E2QlsapBrlYm2UaR8bWbL4bZw\"\n",
    "\n",
    "            genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "            model = ChatGoogleGenerativeAI(model=\"gemini-pro\",google_api_key=GOOGLE_API_KEY,\n",
    "                                        temperature=0.2,convert_system_message_to_human=True)\n",
    "\n",
    "            # template = \"\"\"You are an assistant that helps with CVE data. Only use the context provided. Respond with relevant CVE details.\n",
    "            # {context}\n",
    "            # Question: {question}\n",
    "            # Helpful Answer:\"\"\"\n",
    "            \n",
    "            # QA_CHAIN_PROMPT = PromptTemplate.from_template(template)# Run chain\n",
    "            # print(QA_CHAIN_PROMPT)\n",
    "            # qa_chain = LLMChain(\n",
    "            # llm=model,\n",
    "            # prompt=QA_CHAIN_PROMPT\n",
    "            #    )\n",
    "            # #result = qa_chain.run({\"context\": json_string, \"question\": question})\n",
    "            # result = qa_chain({\"context\": json_string,\"question\": question})\n",
    "            # print(\"#################\")\n",
    "            # print(result)\n",
    "            # print(\"#################\")\n",
    "            # result = qa_chain({\"context\": json_string,\"query\": question})\n",
    "            ########################################################\n",
    "            # messages = [\n",
    "            # # (\"system\", \"You are an assistant that helps with CVE data. tell about CVE-2024-4405\\n\" + \"this is the context\\n\" + \"Context:\"+ json_string),\n",
    "            # (\"system\",  \"Use this data to answer the question in detail \\n\" + json_string),\n",
    "            # (\"human\", question),\n",
    "            \n",
    "            # ]\n",
    "            # print(messages)\n",
    "            # result = model.invoke(messages)\n",
    "            # print(result)\n",
    "            ######################################################\n",
    "            chain = self.get_conversational_chain()\n",
    "\n",
    "    \n",
    "            result = chain(\n",
    "                {\"input_documents\":self.json_string_to_docs(json_string), \"question\": question }\n",
    "                , return_only_outputs=True)\n",
    "\n",
    "            print(result)\n",
    "\n",
    "            formatted_output = result['output_text'].replace('**', '')\n",
    "\n",
    "            self.display_message(f'Question: {question}', 'blue')\n",
    "            self.display_message(f'Answer:\\n{formatted_output}', 'green')\n",
    "            time.sleep(5)\n",
    "\n",
    "            return formatted_output\n",
    "            ######################################################\n",
    "            # result = model([\n",
    "            # #SystemMessage(content=\"Provide details related to the question using the context\"),\n",
    "            # HumanMessage(content=\"Context:\" + json_string + \"\\n Question:\"+question)\n",
    "\n",
    "                \n",
    "            # ]).content\n",
    "            # self.display_message(f'Question: {question}', 'blue')\n",
    "            # self.display_message(f'Answer:\\n{result}', 'green')\n",
    "            ######################################################\n",
    "    def display_message(self, message, color):\n",
    "        self.results_output.configure(state='normal')\n",
    "        self.results_output.insert(tk.END, message + '\\n', (color,))\n",
    "        self.results_output.configure(state='disabled')\n",
    "        self.results_output.see(tk.END)\n",
    "\n",
    "    def save_results(self, results):\n",
    "        \"\"\"Saves the results (questions, expected answers, actual answers) to a JSON file.\"\"\"\n",
    "        with open(self.output_file, 'w', encoding='utf-8') as file:\n",
    "            json.dump(results, file, indent=4)\n",
    "    \n",
    "    def process_questions(self):\n",
    "        \"\"\"Processes questions from the loaded JSON and saves the results.\"\"\"\n",
    "        questions_data = self.load_questions()\n",
    "        results = []\n",
    "\n",
    "        for item in questions_data:\n",
    "            question = item['question']\n",
    "            expected_answer = item.get('expected_answer', 'No expected answer provided')\n",
    "            # actual_answer = self.answer_question(question)\n",
    "            actual_answer =  self.handle_question(question)\n",
    "\n",
    "            result = {\n",
    "                'question': question,\n",
    "                'expected_answer': expected_answer,\n",
    "                'actual_answer': actual_answer\n",
    "            }\n",
    "\n",
    "            results.append(result)\n",
    "\n",
    "        self.save_results(results)\n",
    "    \n",
    "    def setup_interface(self):\n",
    "        root = tk.Tk()\n",
    "        root.title(\"ChatNVD Interface Gemini\")\n",
    "\n",
    "        self.text_input = tk.Entry(root, width=100)\n",
    "        self.text_input.pack(pady=10)\n",
    "        self.text_input.bind('<Return>', lambda event: self.handle_question())\n",
    "\n",
    "        self.results_output = scrolledtext.ScrolledText(root, width=100, height=30, wrap=tk.WORD)\n",
    "        self.results_output.pack(pady=10)\n",
    "        self.results_output.tag_configure('blue', foreground='blue')\n",
    "        self.results_output.tag_configure('green', foreground='green')\n",
    "        self.results_output.tag_configure('red', foreground='red')\n",
    "        self.results_output.configure(state='disabled')\n",
    "\n",
    "        # Button to process questions and save results\n",
    "        process_button = tk.Button(root, text=\"Process Questions\", command=self.process_questions)\n",
    "        process_button.pack(pady=10)\n",
    "\n",
    "        root.mainloop()\n",
    "\n",
    "# Initialize the chatbot with multiple files\n",
    "file_paths = [\n",
    "    'nvdcve-1.1-recent_updated.json',\n",
    "    'nvdcve-1.1-modified_updated.json',\n",
    "    'nvdcve-1.1-2024_updated.json',\n",
    " 'nvdcve-1.1-2023_updated.json',\n",
    " 'nvdcve-1.1-2022_updated.json',\n",
    " 'nvdcve-1.1-2021_updated.json',\n",
    " 'nvdcve-1.1-2020_updated.json',\n",
    " 'nvdcve-1.1-2019_updated.json',\n",
    " 'nvdcve-1.1-2018_updated.json',\n",
    " 'nvdcve-1.1-2017_updated.json',\n",
    " 'nvdcve-1.1-2016_updated.json',\n",
    " 'nvdcve-1.1-2015_updated.json',\n",
    " 'nvdcve-1.1-2014_updated.json',\n",
    " 'nvdcve-1.1-2013_updated.json',\n",
    " 'nvdcve-1.1-2012_updated.json',\n",
    " 'nvdcve-1.1-2011_updated.json',\n",
    " 'nvdcve-1.1-2010_updated.json',\n",
    " 'nvdcve-1.1-2009_updated.json',\n",
    " 'nvdcve-1.1-2008_updated.json',\n",
    " 'nvdcve-1.1-2007_updated.json',\n",
    " 'nvdcve-1.1-2006_updated.json',\n",
    " 'nvdcve-1.1-2005_updated.json',\n",
    " 'nvdcve-1.1-2004_updated.json',\n",
    " 'nvdcve-1.1-2003_updated.json',\n",
    " 'nvdcve-1.1-2002_updated.json'\n",
    "]\n",
    "api_key = 'your-api-key'\n",
    "questions_file = 'questions1.json'  # JSON file with questions and expected answers\n",
    "output_file = 'gemini_output_results_5.json'  # JSON file to save results\n",
    "api_key = 'your-api-key'\n",
    "chatbot = Chatbot(file_paths, api_key, questions_file, output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
