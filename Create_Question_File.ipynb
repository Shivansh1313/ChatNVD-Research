{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions have been generated and saved to questions1.json\n"
     ]
    }
   ],
   "source": [
    "#This file creates question file with question and expected answer\n",
    "import json\n",
    "import random\n",
    "\n",
    "# def load_cve_data(cve_file):\n",
    "#     \"\"\"Loads CVE data from a JSON file.\"\"\"\n",
    "#     with open(cve_file, 'r', encoding='utf-8') as file:\n",
    "#         data = json.load(file)\n",
    "#     return data\n",
    "def load_cve_data(file_paths):    \n",
    "        all_data = []\n",
    "        for file_path in file_paths:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "                all_data.extend(data)\n",
    "        return all_data\n",
    "\n",
    "def find_value_by_key(nested_dict, target_key):\n",
    "    if isinstance(nested_dict, dict):\n",
    "        for key, value in nested_dict.items():\n",
    "            if key == target_key:\n",
    "                return value\n",
    "            # Recursively check nested dictionaries\n",
    "            found_value = find_value_by_key(value, target_key)\n",
    "            if found_value is not None:\n",
    "                return found_value\n",
    "    elif isinstance(nested_dict, list):\n",
    "        for item in nested_dict:\n",
    "            found_value = find_value_by_key(item, target_key)\n",
    "            if found_value is not None:\n",
    "                return found_value\n",
    "    return None\n",
    "\n",
    "def get_nested_value(data, keys, default=\"No data available\"):\n",
    "    \"\"\"Retrieves a nested value from a dictionary given a list of keys.\"\"\"\n",
    "    for key in keys:\n",
    "        data = data.get(key, {})\n",
    "    return data if data else default\n",
    "\n",
    "def generate_question(cve, field):\n",
    "    \"\"\"Generates a question and expected answer for a given field of the CVE.\"\"\"\n",
    "    if field == \"PublishedDate\":\n",
    "        question = f\"What is the published date of {cve['CVE_ID']}\"\n",
    "        #expected_answer = cve.get('PublishedDate', 'No data available')\n",
    "        expected_answer =find_value_by_key(cve, 'PublishedDate')\n",
    "    elif field == \"Description\":\n",
    "        question = f\"What is the description of {cve['CVE_ID']}\"\n",
    "        #expected_answer = cve.get('Description', 'No data available')\n",
    "        expected_answer =find_value_by_key(cve, 'Description')\n",
    "    elif field == \"ExploitabilityScore\":\n",
    "        # Retrieve ExploitabilityScore from the nested structure\n",
    "        #expected_answer = get_nested_value(cve, ['Impact', 'baseMetricV3', 'exploitabilityScore'])\n",
    "        expected_answer =find_value_by_key(cve, 'exploitabilityScore')\n",
    "        question = f\"What is the exploitability score of {cve['CVE_ID']}\"\n",
    "    elif field == \"ImpactScore\":\n",
    "        # Retrieve ImpactScore from the nested structure\n",
    "        #expected_answer = get_nested_value(cve, ['Impact', 'baseMetricV3', 'impactScore'])\n",
    "        expected_answer =find_value_by_key(cve, 'impactScore')\n",
    "        question = f\"What is the impact score of {cve['CVE_ID']}\"\n",
    "    elif field == \"BaseScore\":\n",
    "        # Retrieve BaseScore from the nested structure\n",
    "        #expected_answer = get_nested_value(cve, ['Impact', 'baseMetricV3', 'cvssV3', 'baseScore'])\n",
    "        expected_answer =find_value_by_key(cve, 'baseScore')\n",
    "        question = f\"What is the base score of {cve['CVE_ID']}\"\n",
    "    \n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"expected_answer\": expected_answer\n",
    "    }\n",
    "\n",
    "def generate_questions(cve_data, num_questions=5):\n",
    "    \"\"\"Generates random questions for the specified number of CVEs.\"\"\"\n",
    "    selected_cves = random.sample(cve_data, num_questions)\n",
    "    questions = []\n",
    "    \n",
    "    for cve in selected_cves:\n",
    "        # Generate questions for each required field\n",
    "        questions.append(generate_question(cve, \"PublishedDate\"))\n",
    "        questions.append(generate_question(cve, \"Description\"))\n",
    "        questions.append(generate_question(cve, \"ExploitabilityScore\"))\n",
    "        questions.append(generate_question(cve, \"ImpactScore\"))\n",
    "        questions.append(generate_question(cve, \"BaseScore\"))\n",
    "\n",
    "    return questions\n",
    "\n",
    "def save_questions_to_file(questions, output_file):\n",
    "    \"\"\"Saves the generated questions to a JSON file.\"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        json.dump(questions, file, indent=4)\n",
    "\n",
    "# Load CVE data from a file\n",
    "cve_file = [\n",
    "      'nvdcve-1.1-2024_updated.json',\n",
    "      'nvdcve-1.1-2023_updated.json',\n",
    " 'nvdcve-1.1-2022_updated.json',\n",
    " 'nvdcve-1.1-2021_updated.json',\n",
    " 'nvdcve-1.1-2020_updated.json',\n",
    " 'nvdcve-1.1-2019_updated.json',\n",
    " 'nvdcve-1.1-2018_updated.json',\n",
    " 'nvdcve-1.1-2017_updated.json',\n",
    " 'nvdcve-1.1-2016_updated.json',\n",
    " 'nvdcve-1.1-2015_updated.json',\n",
    " 'nvdcve-1.1-2014_updated.json',\n",
    " 'nvdcve-1.1-2013_updated.json',\n",
    " 'nvdcve-1.1-2012_updated.json',\n",
    " 'nvdcve-1.1-2011_updated.json',\n",
    " 'nvdcve-1.1-2010_updated.json',\n",
    " 'nvdcve-1.1-2009_updated.json',\n",
    " 'nvdcve-1.1-2008_updated.json',\n",
    " 'nvdcve-1.1-2007_updated.json',\n",
    " 'nvdcve-1.1-2006_updated.json',\n",
    " 'nvdcve-1.1-2005_updated.json',\n",
    " 'nvdcve-1.1-2004_updated.json',\n",
    " 'nvdcve-1.1-2003_updated.json',\n",
    " 'nvdcve-1.1-2002_updated.json'\n",
    "              \n",
    "              ]\n",
    "cve_data = load_cve_data(cve_file)\n",
    "\n",
    "# Generate questions from random CVE IDs\n",
    "questions = generate_questions(cve_data, num_questions=5)\n",
    "\n",
    "# Save the generated questions to a JSON file\n",
    "output_file = 'questions1.json'\n",
    "save_questions_to_file(questions, output_file)\n",
    "\n",
    "print(f\"Questions have been generated and saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.00\n",
      "Recall: 0.20\n",
      "F1 Score: 0.33\n"
     ]
    }
   ],
   "source": [
    "#This file evaluated the output file from different LLMs\n",
    "import json\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def load_json(file_path):\n",
    "    \"\"\"Loads the JSON file with questions, expected answers, and actual answers.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def preprocess_answer(answer):\n",
    "    \"\"\"Basic preprocessing to convert answers to lowercase and strip unnecessary characters.\"\"\"\n",
    "    return answer.lower().strip()\n",
    "\n",
    "def compare_answers(expected, actual):\n",
    "    \"\"\"Token-based comparison for textual answers using cosine similarity.\"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([expected, actual])\n",
    "    similarity = cosine_similarity(vectors[0], vectors[1])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def evaluate_answers(data):\n",
    "    \"\"\"Evaluates the actual answers against the expected answers using token overlap.\"\"\"\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    thresholds = 0.75  # Cosine similarity threshold for text match\n",
    "    \n",
    "    for item in data:\n",
    "        expected_answer = str(item['expected_answer']).lower()\n",
    "        actual_answer = str(item['actual_answer']).lower()\n",
    "        \n",
    "        if isinstance(item['expected_answer'], (int, float)):  # Numeric comparison\n",
    "            y_true.append(1)\n",
    "            y_pred.append(1 if expected_answer == actual_answer else 0)\n",
    "        else:  # Textual comparison\n",
    "            similarity = compare_answers(preprocess_answer(expected_answer), preprocess_answer(actual_answer))\n",
    "            y_true.append(1)  # Expected to match\n",
    "            y_pred.append(1 if similarity >= thresholds else 0)\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "# Load the JSON file\n",
    "file_path = 'gpt_output_results.json'  # Replace with your JSON file path\n",
    "data = load_json(file_path)\n",
    "\n",
    "# Evaluate the answers\n",
    "precision, recall, f1 = evaluate_answers(data)\n",
    "\n",
    "# Print results\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Results:\n",
      "\n",
      "Question 1: What is the published date of CVE-2023-49255\n",
      "Expected Answer: 2024-01-12T15:15Z\n",
      "Actual Answer: The published date of CVE-2023-49255 is 2024-01-12T15:15Z.\n",
      "Similarity Score: 0.45\n",
      "Correct: No\n",
      "\n",
      "Question 2: What is the description of CVE-2023-49255\n",
      "Expected Answer: The router console is accessible without authentication at \"data\" field, and while a user needs to be logged in in order to modify the configuration, the session state is shared. If any other user is currently logged in, the anonymous user can execute commands in the context of the authenticated one. If the logged in user has administrative privileges, it is possible to use webadmin service configuration commands to create a new admin user with a chosen password.\n",
      "Actual Answer: The description of CVE-2023-49255 is: \"The router console is accessible without authentication at 'data' field, and while a user needs to be logged in in order to modify the configuration, the session state is shared. If any other user is currently logged in, the anonymous user can execute commands in the context of the authenticated one. If the logged in user has administrative privileges, it is possible to use webadmin service configuration commands to create a new admin user with a chosen password.\"\n",
      "Similarity Score: 0.98\n",
      "Correct: Yes\n",
      "\n",
      "Question 3: What is the exploitability score of CVE-2023-49255\n",
      "Expected Answer: 3.9\n",
      "Actual Answer: The exploitability score of CVE-2023-49255 is 3.9.\n",
      "Similarity Score: 0.00\n",
      "Correct: No\n",
      "\n",
      "Question 4: What is the impact score of CVE-2023-49255\n",
      "Expected Answer: 5.9\n",
      "Actual Answer: The impact score of CVE-2023-49255 is 5.9.\n",
      "Similarity Score: 0.00\n",
      "Correct: No\n",
      "\n",
      "Question 5: What is the base score of CVE-2023-49255\n",
      "Expected Answer: 9.8\n",
      "Actual Answer: The base score of CVE-2023-49255 is 9.8.\n",
      "Similarity Score: 0.00\n",
      "Correct: No\n",
      "\n",
      "Question 6: What is the published date of CVE-2023-43726\n",
      "Expected Answer: 2023-09-30T22:15Z\n",
      "Actual Answer: The published date of CVE-2023-43726 is 2023-09-30T22:15Z.\n",
      "Similarity Score: 0.55\n",
      "Correct: No\n",
      "\n",
      "Question 7: What is the description of CVE-2023-43726\n",
      "Expected Answer: Os Commerce is currently susceptible to a Cross-Site Scripting (XSS) vulnerability.\n",
      "This vulnerability allows attackers to inject JS through the \"orders_products_status_manual_name_long[1]\" parameter,\n",
      "potentially leading to unauthorized execution of scripts within a user's web browser.\n",
      "Actual Answer: The description of CVE-2023-43726 is: \"Os Commerce is currently susceptible to a Cross-Site Scripting (XSS) vulnerability. This vulnerability allows attackers to inject JS through the 'orders_products_status_manual_name_long[1]' parameter, potentially leading to unauthorized execution of scripts within a user's web browser.\"\n",
      "Similarity Score: 0.90\n",
      "Correct: Yes\n",
      "\n",
      "Question 8: What is the exploitability score of CVE-2023-43726\n",
      "Expected Answer: 2.3\n",
      "Actual Answer: The exploitability score of CVE-2023-43726 is 2.3.\n",
      "Similarity Score: 0.00\n",
      "Correct: No\n",
      "\n",
      "Question 9: What is the impact score of CVE-2023-43726\n",
      "Expected Answer: 2.7\n",
      "Actual Answer: The impact score of CVE-2023-43726 is 2.7.\n",
      "Similarity Score: 0.00\n",
      "Correct: No\n",
      "\n",
      "Question 10: What is the base score of CVE-2023-43726\n",
      "Expected Answer: 5.4\n",
      "Actual Answer: The base score of CVE-2023-43726 is 5.4.\n",
      "Similarity Score: 0.00\n",
      "Correct: No\n",
      "\n",
      "Question 11: What is the published date of CVE-2023-34277\n",
      "Expected Answer: 2024-05-03T02:15Z\n",
      "Actual Answer: The published date of CVE-2023-34277 is 2024-05-03T02:15Z.\n",
      "Similarity Score: 0.45\n",
      "Correct: No\n",
      "\n",
      "Question 12: What is the description of CVE-2023-34277\n",
      "Expected Answer: D-Link DIR-2150 SetSysEmailSettings AccountName Command Injection Remote Code Execution Vulnerability. This vulnerability allows network-adjacent attackers to execute arbitrary code on affected installations of D-Link DIR-2150 routers. Although authentication is required to exploit this vulnerability, the existing authentication mechanism can be bypassed.\n",
      "\n",
      "The specific flaw exists within the SOAP API interface, which listens on TCP port 80 by default. The issue results from the lack of proper validation of a user-supplied string before using it to execute a system call. An attacker can leverage this vulnerability to execute code in the context of root. Was ZDI-CAN-20555.\n",
      "Actual Answer: The description of CVE-2023-34277 is: \"D-Link DIR-2150 SetSysEmailSettings AccountName Command Injection Remote Code Execution Vulnerability. This vulnerability allows network-adjacent attackers to execute arbitrary code on affected installations of D-Link DIR-2150 routers. Although authentication is required to exploit this vulnerability, the existing authentication mechanism can be bypassed. The specific flaw exists within the SOAP API interface, which listens on TCP port 80 by default. The issue results from the lack of proper validation of a user-supplied string before using it to execute a system call. An attacker can leverage this vulnerability to execute code in the context of root. Was ZDI-CAN-20555.\"\n",
      "Similarity Score: 0.98\n",
      "Correct: Yes\n",
      "\n",
      "Question 13: What is the exploitability score of CVE-2023-34277\n",
      "Expected Answer: No data available\n",
      "Actual Answer: Data not available.\n",
      "Similarity Score: 0.50\n",
      "Correct: No\n",
      "\n",
      "Question 14: What is the impact score of CVE-2023-34277\n",
      "Expected Answer: No data available\n",
      "Actual Answer: Data not available.\n",
      "Similarity Score: 0.50\n",
      "Correct: No\n",
      "\n",
      "Question 15: What is the base score of CVE-2023-34277\n",
      "Expected Answer: No data available\n",
      "Actual Answer: Data not available.\n",
      "Similarity Score: 0.50\n",
      "Correct: No\n",
      "\n",
      "Question 16: What is the published date of CVE-2023-6916\n",
      "Expected Answer: 2024-04-10T16:15Z\n",
      "Actual Answer: The published date of CVE-2023-6916 is 2024-04-10T16:15Z.\n",
      "Similarity Score: 0.45\n",
      "Correct: No\n",
      "\n",
      "Question 17: What is the description of CVE-2023-6916\n",
      "Expected Answer: Audit records for OpenAPI requests may include sensitive information.\n",
      "\n",
      "\n",
      "\n",
      "This could lead to unauthorized accesses and privilege escalation.\n",
      "Actual Answer: The description of CVE-2023-6916 is: \"Audit records for OpenAPI requests may include sensitive information. This could lead to unauthorized accesses and privilege escalation.\"\n",
      "Similarity Score: 0.75\n",
      "Correct: Yes\n",
      "\n",
      "Question 18: What is the exploitability score of CVE-2023-6916\n",
      "Expected Answer: No data available\n",
      "Actual Answer: Data not available.\n",
      "Similarity Score: 0.50\n",
      "Correct: No\n",
      "\n",
      "Question 19: What is the impact score of CVE-2023-6916\n",
      "Expected Answer: No data available\n",
      "Actual Answer: Data not available.\n",
      "Similarity Score: 0.50\n",
      "Correct: No\n",
      "\n",
      "Question 20: What is the base score of CVE-2023-6916\n",
      "Expected Answer: No data available\n",
      "Actual Answer: Data not available.\n",
      "Similarity Score: 0.50\n",
      "Correct: No\n",
      "\n",
      "Question 21: What is the published date of CVE-2023-32079\n",
      "Expected Answer: 2023-08-24T23:15Z\n",
      "Actual Answer: The published date of CVE-2023-32079 is 2023-08-24T23:15Z.\n",
      "Similarity Score: 0.55\n",
      "Correct: No\n",
      "\n",
      "Question 22: What is the description of CVE-2023-32079\n",
      "Expected Answer: Netmaker makes networks with WireGuard. A Mass assignment vulnerability was found in versions prior to 0.17.1 and 0.18.6 that allows a non-admin user to escalate privileges to those of an admin user. The issue is patched in 0.17.1 and fixed in 0.18.6. If Users are using 0.17.1, they should run `docker pull gravitl/netmaker:v0.17.1` and `docker-compose up -d`. This will switch them to the patched users If users are using v0.18.0-0.18.5, they should upgrade to v0.18.6 or later. As a workaround, someone using version 0.17.1 can pull the latest docker image of the backend and restart the server.\n",
      "Actual Answer: The description of CVE-2023-32079 is: \"Netmaker makes networks with WireGuard. A Mass assignment vulnerability was found in versions prior to 0.17.1 and 0.18.6 that allows a non-admin user to escalate privileges to those of an admin user. The issue is patched in 0.17.1 and fixed in 0.18.6. If Users are using 0.17.1, they should run `docker pull gravitl/netmaker:v0.17.1` and `docker-compose up -d`. This will switch them to the patched users If users are using v0.18.0-0.18.5, they should upgrade to v0.18.6 or later. As a workaround, someone using version 0.17.1 can pull the latest docker image of the backend and restart the server.\"\n",
      "Similarity Score: 0.98\n",
      "Correct: Yes\n",
      "\n",
      "Question 23: What is the exploitability score of CVE-2023-32079\n",
      "Expected Answer: 2.8\n",
      "Actual Answer: The exploitability score of CVE-2023-32079 is 2.8.\n",
      "Similarity Score: 0.00\n",
      "Correct: No\n",
      "\n",
      "Question 24: What is the impact score of CVE-2023-32079\n",
      "Expected Answer: 5.9\n",
      "Actual Answer: The impact score of CVE-2023-32079 is 5.9.\n",
      "Similarity Score: 0.00\n",
      "Correct: No\n",
      "\n",
      "Question 25: What is the base score of CVE-2023-32079\n",
      "Expected Answer: 8.8\n",
      "Actual Answer: The base score of CVE-2023-32079 is 8.8.\n",
      "Similarity Score: 0.00\n",
      "Correct: No\n",
      "\n",
      "Overall Results:\n",
      "Precision: 1.00\n",
      "Recall: 0.20\n",
      "F1 Score: 0.33\n"
     ]
    }
   ],
   "source": [
    "#this approach shows all the details and uses tokenization for all questions\n",
    "import json\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def load_json(file_path):\n",
    "    \"\"\"Loads the JSON file with questions, expected answers, and actual answers.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def preprocess_answer(answer):\n",
    "    \"\"\"Basic preprocessing to convert answers to lowercase and strip unnecessary characters.\"\"\"\n",
    "    return answer.lower().strip()\n",
    "\n",
    "def compare_answers(expected, actual):\n",
    "    \"\"\"Token-based comparison for textual answers using cosine similarity.\"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([expected, actual])\n",
    "    similarity = cosine_similarity(vectors[0], vectors[1])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def evaluate_answers(data, threshold=0.75):\n",
    "    \"\"\"Evaluates the actual answers against the expected answers and displays results for each question.\"\"\"\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    print(\"Detailed Results:\\n\")\n",
    "    \n",
    "    for idx, item in enumerate(data):\n",
    "        expected_answer = str(item['expected_answer']).lower()\n",
    "        actual_answer = str(item['actual_answer']).lower()\n",
    "        correct = False\n",
    "        score = 0\n",
    "        \n",
    "        # Compare numeric answers directly\n",
    "        if isinstance(item['expected_answer'], (int, float)):\n",
    "            correct = expected_answer == actual_answer\n",
    "            score = 1.0 if correct else 0.0\n",
    "        else:\n",
    "            # Use cosine similarity for text-based answers\n",
    "            score = compare_answers(preprocess_answer(expected_answer), preprocess_answer(actual_answer))\n",
    "            correct = score >= threshold\n",
    "        \n",
    "        y_true.append(1)  # Expected to match\n",
    "        y_pred.append(1 if correct else 0)\n",
    "        \n",
    "        # Display the result for this question\n",
    "        print(f\"Question {idx + 1}: {item['question']}\")\n",
    "        print(f\"Expected Answer: {item['expected_answer']}\")\n",
    "        print(f\"Actual Answer: {item['actual_answer']}\")\n",
    "        print(f\"Similarity Score: {score:.2f}\")\n",
    "        print(f\"Correct: {'Yes' if correct else 'No'}\\n\")\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "# Load the JSON file\n",
    "file_path = 'gpt_output_results.json'  # Replace with your JSON file path\n",
    "data = load_json(file_path)\n",
    "\n",
    "# Evaluate the answers and display detailed results\n",
    "precision, recall, f1 = evaluate_answers(data, threshold=0.75)\n",
    "\n",
    "# Print overall precision, recall, and F1 score\n",
    "print(\"Overall Results:\")\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Results:\n",
      "\n",
      "Question 1: What is the published date of CVE-2023-47196\n",
      "Expected Answer: 2024-01-23T21:15Z\n",
      "Actual Answer: The published date of CVE-2023-47196 is January 23, 2024.\n",
      "Score: 0.00\n",
      "Correct: No\n",
      "\n",
      "Question 2: What is the description of CVE-2023-47196\n",
      "Expected Answer: An origin validation vulnerability in the Trend Micro Apex One security agent could allow a local attacker to escalate privileges on affected installations.\n",
      "\n",
      "Please note: an attacker must first obtain the ability to execute low-privileged code on the target system in order to exploit this vulnerability.\n",
      "\n",
      "This vulnerability is similar to, but not identical to, CVE-2023-47197.\n",
      "Actual Answer: The description of CVE-2023-47196 is: \"An origin validation vulnerability in the Trend Micro Apex One security agent could allow a local attacker to escalate privileges on affected installations. Please note: an attacker must first obtain the ability to execute low-privileged code on the target system in order to exploit this vulnerability. This vulnerability is similar to, but not identical to, CVE-2023-47197.\"\n",
      "Score: 0.96\n",
      "Correct: Yes\n",
      "\n",
      "Question 3: What is the exploitability score of CVE-2023-47196\n",
      "Expected Answer: 1.8\n",
      "Actual Answer: The exploitability score of CVE-2023-47196 is 1.8.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 4: What is the impact score of CVE-2023-47196\n",
      "Expected Answer: 5.9\n",
      "Actual Answer: The impact score of CVE-2023-47196 is 5.9.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 5: What is the base score of CVE-2023-47196\n",
      "Expected Answer: 7.8\n",
      "Actual Answer: The base score of CVE-2023-47196 is 7.8.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 6: What is the published date of CVE-2023-0660\n",
      "Expected Answer: 2023-03-27T16:15Z\n",
      "Actual Answer: The published date of CVE-2023-0660 is March 27, 2023.\n",
      "Score: 0.00\n",
      "Correct: No\n",
      "\n",
      "Question 7: What is the description of CVE-2023-0660\n",
      "Expected Answer: The Smart Slider 3 WordPress plugin before 3.5.1.14 does not properly validate and escape some of its shortcode attributes before outputting them back in a page/post where the shortcode is embed, which could allow users with the contributor role and above to perform Stored Cross-Site Scripting attacks\n",
      "Actual Answer: The description of CVE-2023-0660 is: \"The Smart Slider 3 WordPress plugin before 3.5.1.14 does not properly validate and escape some of its shortcode attributes before outputting them back in a page/post where the shortcode is embed, which could allow users with the contributor role and above to perform Stored Cross-Site Scripting attacks.\"\n",
      "Score: 0.93\n",
      "Correct: Yes\n",
      "\n",
      "Question 8: What is the exploitability score of CVE-2023-0660\n",
      "Expected Answer: 2.3\n",
      "Actual Answer: The exploitability score of CVE-2023-0660 is 2.3.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 9: What is the impact score of CVE-2023-0660\n",
      "Expected Answer: 2.7\n",
      "Actual Answer: The impact score of CVE-2023-0660 is 2.7.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 10: What is the base score of CVE-2023-0660\n",
      "Expected Answer: 5.4\n",
      "Actual Answer: The base score of CVE-2023-0660 is 5.4.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 11: What is the published date of CVE-2023-1910\n",
      "Expected Answer: 2023-06-09T06:15Z\n",
      "Actual Answer: The published date of CVE-2023-1910 is June 9, 2023.\n",
      "Score: 0.00\n",
      "Correct: No\n",
      "\n",
      "Question 12: What is the description of CVE-2023-1910\n",
      "Expected Answer: The Getwid – Gutenberg Blocks plugin for WordPress is vulnerable to unauthorized modification of data due to an insufficient capability check on the get_remote_templates function in versions up to, and including, 1.8.3. This makes it possible for authenticated attackers with subscriber-level permissions or above to flush the remote template cache. Cached template information can also be accessed via this endpoint but these are not considered sensitive as they are publicly accessible from the developer's site.\n",
      "Actual Answer: The description of CVE-2023-1910 is: \"The Getwid – Gutenberg Blocks plugin for WordPress is vulnerable to unauthorized modification of data due to an insufficient capability check on the get_remote_templates function in versions up to, and including, 1.8.3. This makes it possible for authenticated attackers with subscriber-level permissions or above to flush the remote template cache. Cached template information can also be accessed via this endpoint but these are not considered sensitive as they are publicly accessible from the developer's site.\"\n",
      "Score: 0.96\n",
      "Correct: Yes\n",
      "\n",
      "Question 13: What is the exploitability score of CVE-2023-1910\n",
      "Expected Answer: 2.8\n",
      "Actual Answer: The exploitability score of CVE-2023-1910 is 2.8.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 14: What is the impact score of CVE-2023-1910\n",
      "Expected Answer: 1.4\n",
      "Actual Answer: The impact score of CVE-2023-1910 is 1.4.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 15: What is the base score of CVE-2023-1910\n",
      "Expected Answer: 4.3\n",
      "Actual Answer: The base score of CVE-2023-1910 is 4.3.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 16: What is the published date of CVE-2023-25466\n",
      "Expected Answer: 2023-08-30T16:15Z\n",
      "Actual Answer: The published date of CVE-2023-25466 is August 30, 2023.\n",
      "Score: 0.00\n",
      "Correct: No\n",
      "\n",
      "Question 17: What is the description of CVE-2023-25466\n",
      "Expected Answer: Unauth. Reflected Cross-Site Scripting (XSS) vulnerability in Mahlamusa Who Hit The Page – Hit Counter plugin <= 1.4.14.3 versions.\n",
      "Actual Answer: The description of CVE-2023-25466 is: \"Unauth. Reflected Cross-Site Scripting (XSS) vulnerability in Mahlamusa Who Hit The Page – Hit Counter plugin <= 1.4.14.3 versions.\"\n",
      "Score: 0.80\n",
      "Correct: Yes\n",
      "\n",
      "Question 18: What is the exploitability score of CVE-2023-25466\n",
      "Expected Answer: 2.8\n",
      "Actual Answer: The exploitability score of CVE-2023-25466 is 2.8.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 19: What is the impact score of CVE-2023-25466\n",
      "Expected Answer: 2.7\n",
      "Actual Answer: The impact score of CVE-2023-25466 is 2.7.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 20: What is the base score of CVE-2023-25466\n",
      "Expected Answer: 6.1\n",
      "Actual Answer: The base score of CVE-2023-25466 is 6.1.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 21: What is the published date of CVE-2023-46559\n",
      "Expected Answer: 2023-10-25T18:17Z\n",
      "Actual Answer: The published date of CVE-2023-46559 is October 25, 2023.\n",
      "Score: 0.00\n",
      "Correct: No\n",
      "\n",
      "Question 22: What is the description of CVE-2023-46559\n",
      "Expected Answer: TOTOLINK X2000R Gh v1.0.0-B20230221.0948.web was discovered to contain a stack overflow via the function formIPv6Addr.\n",
      "Actual Answer: The description of CVE-2023-46559 is: \"TOTOLINK X2000R Gh v1.0.0-B20230221.0948.web was discovered to contain a stack overflow via the function formIPv6Addr.\"\n",
      "Score: 0.77\n",
      "Correct: Yes\n",
      "\n",
      "Question 23: What is the exploitability score of CVE-2023-46559\n",
      "Expected Answer: 3.9\n",
      "Actual Answer: The exploitability score of CVE-2023-46559 is 3.9.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 24: What is the impact score of CVE-2023-46559\n",
      "Expected Answer: 5.9\n",
      "Actual Answer: The impact score of CVE-2023-46559 is 5.9.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 25: What is the base score of CVE-2023-46559\n",
      "Expected Answer: 9.8\n",
      "Actual Answer: The base score of CVE-2023-46559 is 9.8.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Overall Results:\n",
      "Precision: 1.00\n",
      "Recall: 0.80\n",
      "F1 Score: 0.89\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n",
    "def load_json(file_path):\n",
    "    \"\"\"Loads the JSON file with questions, expected answers, and actual answers.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def preprocess_answer(answer):\n",
    "    \"\"\"Basic preprocessing to convert answers to lowercase and strip unnecessary characters.\"\"\"\n",
    "    return answer.lower().strip()\n",
    "\n",
    "def compare_textual_answers(expected, actual):\n",
    "    \"\"\"Token-based comparison for textual answers using cosine similarity (for descriptions).\"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([expected, actual])\n",
    "    similarity = cosine_similarity(vectors[0], vectors[1])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def evaluate_answers(data, threshold=0.75):\n",
    "    \"\"\"Evaluates the actual answers against the expected answers and displays results for each question.\"\"\"\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    print(\"Detailed Results:\\n\")\n",
    "    \n",
    "    for idx, item in enumerate(data):\n",
    "        expected_answer = str(item['expected_answer']).lower()\n",
    "        actual_answer = str(item['actual_answer']).lower()\n",
    "        correct = False\n",
    "        score = 0\n",
    "        \n",
    "        # Special case for description: Use token-based comparison\n",
    "        if \"description\" in item['question'].lower():\n",
    "            score = compare_textual_answers(preprocess_answer(expected_answer), preprocess_answer(actual_answer))\n",
    "            correct = score >= threshold\n",
    "        else:\n",
    "            # For all other fields, check if the expected answer string is present in the actual answer\n",
    "            correct = expected_answer in actual_answer\n",
    "            score = 1.0 if correct else 0.0\n",
    "        \n",
    "        y_true.append(1)  # Expected to match\n",
    "        y_pred.append(1 if correct else 0)\n",
    "        \n",
    "        # Display the result for this question\n",
    "        print(f\"Question {idx + 1}: {item['question']}\")\n",
    "        print(f\"Expected Answer: {item['expected_answer']}\")\n",
    "        print(f\"Actual Answer: {item['actual_answer']}\")\n",
    "        print(f\"Score: {score:.2f}\")\n",
    "        print(f\"Correct: {'Yes' if correct else 'No'}\\n\")\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "# Load the JSON file\n",
    "file_path = 'gpt_output_results.json'  # Replace with your JSON file path\n",
    "data = load_json(file_path)\n",
    "\n",
    "# Evaluate the answers and display detailed results\n",
    "precision, recall, f1 = evaluate_answers(data, threshold=0.75)\n",
    "\n",
    "# Print overall precision, recall, and F1 score\n",
    "print(\"Overall Results:\")\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Results:\n",
      "\n",
      "No date found in the sentence.\n",
      "Expected data: \n",
      "2016-05-11\n",
      "\n",
      " Actual data: \n",
      "None\n",
      "Question 1: What is the published date of CVE-2016-1044\n",
      "Expected Answer: 2016-05-11T10:59Z\n",
      "Actual Answer: The published date of CVE-2016-1044 is 2016-05-11T10:59Z.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 2: What is the description of CVE-2016-1044\n",
      "Expected Answer: Adobe Reader and Acrobat before 11.0.16, Acrobat and Acrobat Reader DC Classic before 15.006.30172, and Acrobat and Acrobat Reader DC Continuous before 15.016.20039 on Windows and OS X allow attackers to bypass JavaScript API execution restrictions via unspecified vectors, a different vulnerability than CVE-2016-1038, CVE-2016-1039, CVE-2016-1040, CVE-2016-1041, CVE-2016-1042, CVE-2016-1062, and CVE-2016-1117.\n",
      "Actual Answer: The description of CVE-2016-1044 is: \"Adobe Reader and Acrobat before 11.0.16, Acrobat and Acrobat Reader DC Classic before 15.006.30172, and Acrobat and Acrobat Reader DC Continuous before 15.016.20039 on Windows and OS X allow attackers to bypass JavaScript API execution restrictions via unspecified vectors, a different vulnerability than CVE-2016-1038, CVE-2016-1039, CVE-2016-1040, CVE-2016-1041, CVE-2016-1042, CVE-2016-1062, and CVE-2016-1117.\"\n",
      "Score: 0.98\n",
      "Correct: Yes\n",
      "\n",
      "Question 3: What is the exploitability score of CVE-2016-1044\n",
      "Expected Answer: 3.9\n",
      "Actual Answer: The exploitability score of CVE-2016-1044 is 3.9.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 4: What is the impact score of CVE-2016-1044\n",
      "Expected Answer: 6.0\n",
      "Actual Answer: The impact score of CVE-2016-1044 is 6.0.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 5: What is the base score of CVE-2016-1044\n",
      "Expected Answer: 10.0\n",
      "Actual Answer: The base score of CVE-2016-1044 is 10.0.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "No date found in the sentence.\n",
      "Expected data: \n",
      "2023-06-13\n",
      "\n",
      " Actual data: \n",
      "None\n",
      "Question 6: What is the published date of CVE-2023-2638\n",
      "Expected Answer: 2023-06-13T21:15Z\n",
      "Actual Answer: The published date of CVE-2023-2638 is 2023-06-13T21:15Z.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 7: What is the description of CVE-2023-2638\n",
      "Expected Answer: \n",
      "Rockwell Automation's FactoryTalk System Services does not verify that a backup configuration archive is password protected.\n",
      "\n",
      " \n",
      "\n",
      "Improper authorization in FTSSBackupRestore.exe may lead to the loading of malicious configuration archives.  This vulnerability may allow a local, authenticated non-admin user to craft a malicious backup archive, without password protection, that will be loaded by FactoryTalk System Services as a valid backup when a restore procedure takes places. User interaction is required for this vulnerability to be successfully exploited.\n",
      "\n",
      "\n",
      "\n",
      "Actual Answer: The description of CVE-2023-2638 is: \"Rockwell Automation's FactoryTalk System Services does not verify that a backup configuration archive is password protected. Improper authorization in FTSSBackupRestore.exe may lead to the loading of malicious configuration archives. This vulnerability may allow a local, authenticated non-admin user to craft a malicious backup archive, without password protection, that will be loaded by FactoryTalk System Services as a valid backup when a restore procedure takes place. User interaction is required for this vulnerability to be successfully exploited.\"\n",
      "Score: 0.94\n",
      "Correct: Yes\n",
      "\n",
      "Question 8: What is the exploitability score of CVE-2023-2638\n",
      "Expected Answer: 1.3\n",
      "Actual Answer: The exploitability score of CVE-2023-2638 is 1.3.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 9: What is the impact score of CVE-2023-2638\n",
      "Expected Answer: 3.6\n",
      "Actual Answer: The impact score of CVE-2023-2638 is 3.6.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 10: What is the base score of CVE-2023-2638\n",
      "Expected Answer: 5.0\n",
      "Actual Answer: The base score of CVE-2023-2638 is 5.0.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "No date found in the sentence.\n",
      "Expected data: \n",
      "2015-06-30\n",
      "\n",
      " Actual data: \n",
      "None\n",
      "Question 11: What is the published date of CVE-2015-4226\n",
      "Expected Answer: 2015-06-30T15:59Z\n",
      "Actual Answer: The published date of CVE-2015-4226 is 2015-06-30T15:59Z.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 12: What is the description of CVE-2015-4226\n",
      "Expected Answer: The packet-storing feature on Cisco 9900 phones with firmware 9.3(2) does not properly support the RTP protocol, which allows remote attackers to cause a denial of service (device hang) by sending malformed RTP packets after a call is answered, aka Bug ID CSCur39976.\n",
      "Actual Answer: The description of CVE-2015-4226 is: \"The packet-storing feature on Cisco 9900 phones with firmware 9.3(2) does not properly support the RTP protocol, which allows remote attackers to cause a denial of service (device hang) by sending malformed RTP packets after a call is answered, aka Bug ID CSCur39976.\"\n",
      "Score: 0.91\n",
      "Correct: Yes\n",
      "\n",
      "Question 13: What is the exploitability score of CVE-2015-4226\n",
      "Expected Answer: 8.6\n",
      "Actual Answer: The exploitability score of CVE-2015-4226 is 8.6.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 14: What is the impact score of CVE-2015-4226\n",
      "Expected Answer: 6.9\n",
      "Actual Answer: The impact score of CVE-2015-4226 is 6.9.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 15: What is the base score of CVE-2015-4226\n",
      "Expected Answer: 7.1\n",
      "Actual Answer: The base score of CVE-2015-4226 is 7.1.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "No date found in the sentence.\n",
      "Expected data: \n",
      "2018-01-02\n",
      "\n",
      " Actual data: \n",
      "None\n",
      "Question 16: What is the published date of CVE-2017-17098\n",
      "Expected Answer: 2018-01-02T15:29Z\n",
      "Actual Answer: The published date of CVE-2017-17098 is 2018-01-02T15:29Z.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 17: What is the description of CVE-2017-17098\n",
      "Expected Answer: The writeLog function in fn_common.php in gps-server.net GPS Tracking Software (self hosted) through 3.0 allows remote attackers to inject arbitrary PHP code via a crafted request that is mishandled during admin log viewing, as demonstrated by <?php system($_GET[cmd]); ?> in a login request.\n",
      "Actual Answer: The description of CVE-2017-17098 is: \"The writeLog function in fn_common.php in gps-server.net GPS Tracking Software (self hosted) through 3.0 allows remote attackers to inject arbitrary PHP code via a crafted request that is mishandled during admin log viewing, as demonstrated by <?php system($_GET[cmd]); ?> in a login request.\"\n",
      "Score: 0.92\n",
      "Correct: Yes\n",
      "\n",
      "Question 18: What is the exploitability score of CVE-2017-17098\n",
      "Expected Answer: 3.9\n",
      "Actual Answer: The exploitability score of CVE-2017-17098 is 3.9.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 19: What is the impact score of CVE-2017-17098\n",
      "Expected Answer: 5.9\n",
      "Actual Answer: The impact score of CVE-2017-17098 is 5.9.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 20: What is the base score of CVE-2017-17098\n",
      "Expected Answer: 9.8\n",
      "Actual Answer: The base score of CVE-2017-17098 is 9.8.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "No date found in the sentence.\n",
      "Expected data: \n",
      "2005-12-20\n",
      "\n",
      " Actual data: \n",
      "None\n",
      "Question 21: What is the published date of CVE-2005-4366\n",
      "Expected Answer: 2005-12-20T01:03Z\n",
      "Actual Answer: The published date of CVE-2005-4366 is 2005-12-20T01:03Z.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 22: What is the description of CVE-2005-4366\n",
      "Expected Answer: Multiple SQL injection vulnerabilities in DRZES HMS 3.2 allow remote attackers to execute arbitrary SQL commands via the (1) plan_id parameter to (a) domains.php, (b) viewusage.php, (c) pop_accounts.php, (d) databases.php, (e) ftp_users.php, (f) crons.php, (g) pass_dirs.php, (h) zone_files.php, (i) htaccess.php, and (j) software.php; (2) the customerPlanID parameter to viewplan.php; (3) the ref_id parameter to referred_plans.php; (4) customerPlanID parameter to listcharges.php; and (5) the domain parameter to (k) pop_accounts.php, (d) databases.php, (e) ftp_users.php, (f) crons.php, (g) pass_dirs.php, (h) zone_files.php, (i) htaccess.php, and (j) software.php.  NOTE: the viewinvoice.php invoiceID vector is already covered by CVE-2005-4137.\n",
      "Actual Answer: The description of CVE-2005-4366 is: \"Multiple SQL injection vulnerabilities in DRZES HMS 3.2 allow remote attackers to execute arbitrary SQL commands via the (1) plan_id parameter to (a) domains.php, (b) viewusage.php, (c) pop_accounts.php, (d) databases.php, (e) ftp_users.php, (f) crons.php, (g) pass_dirs.php, (h) zone_files.php, (i) htaccess.php, and (j) software.php; (2) the customerPlanID parameter to viewplan.php; (3) the ref_id parameter to referred_plans.php; (4) customerPlanID parameter to listcharges.php; and (5) the domain parameter to (k) pop_accounts.php, (d) databases.php, (e) ftp_users.php, (f) crons.php, (g) pass_dirs.php, (h) zone_files.php, (i) htaccess.php, and (j) software.php. NOTE: the viewinvoice.php invoiceID vector is already covered by CVE-2005-4137.\"\n",
      "Score: 0.99\n",
      "Correct: Yes\n",
      "\n",
      "Question 23: What is the exploitability score of CVE-2005-4366\n",
      "Expected Answer: 10.0\n",
      "Actual Answer: The exploitability score of CVE-2005-4366 is 10.0.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 24: What is the impact score of CVE-2005-4366\n",
      "Expected Answer: 4.9\n",
      "Actual Answer: The impact score of CVE-2005-4366 is 4.9.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 25: What is the base score of CVE-2005-4366\n",
      "Expected Answer: 6.4\n",
      "Actual Answer: The base score of CVE-2005-4366 is 6.4.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Overall Results:\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "# in this date has been parsed into a common format to check it properly\n",
    "\n",
    "import json\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def load_json(file_path):\n",
    "    \"\"\"Loads the JSON file with questions, expected answers, and actual answers.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def preprocess_answer(answer):\n",
    "    \"\"\"Basic preprocessing to convert answers to lowercase and strip unnecessary characters.\"\"\"\n",
    "    return answer.lower().strip()\n",
    "\n",
    "def compare_textual_answers(expected, actual):\n",
    "    \"\"\"Token-based comparison for textual answers using cosine similarity (for descriptions).\"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([expected, actual])\n",
    "    similarity = cosine_similarity(vectors[0], vectors[1])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def parse_date(date_str):\n",
    "    \"\"\"Attempts to parse the date string into a standard format for comparison.\"\"\"\n",
    "    date_formats = [\n",
    "        \"%Y-%m-%dT%H:%MZ\", \"%Y-%m-%d\", \"%Y/%m/%d\", \"%Y-%m-%d %H:%M:%S\", \n",
    "        \"%B %d, %Y\", \"%b %d, %Y\"  # Adding long and short month formats (e.g., \"October 25, 2023\")\n",
    "    ]\n",
    "    for fmt in date_formats:\n",
    "        try:\n",
    "            #return datetime.strptime(date_str, fmt).date()  # Parse to date only\n",
    "            return datetime.strptime(date_str, fmt).strftime(\"%Y-%m-%d\")  # Parse to date only\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_date_2(date_str):\n",
    "\n",
    "    # Regular expression to match the date pattern\n",
    "    date_pattern = r\"([A-Za-z]+\\s\\d{1,2},\\s\\d{4})\"\n",
    "\n",
    "    # Find the date in the sentence\n",
    "    match = re.search(date_pattern, date_str)\n",
    "\n",
    "    # Check if a match is found\n",
    "    if match:\n",
    "        extracted_date = match.group(0)\n",
    "        # Convert the extracted date to a datetime object\n",
    "        try:\n",
    "            date_obj = datetime.strptime(extracted_date, \"%B %d, %Y\")\n",
    "            # Convert to ISO format\n",
    "            iso_date = date_obj.strftime(\"%Y-%m-%d\")\n",
    "            #print(\"Extracted date in ISO format:\", iso_date)\n",
    "            return iso_date\n",
    "        except ValueError:\n",
    "            print(\"Date format is incorrect.\")\n",
    "    else:\n",
    "        print(\"No date found in the sentence.\")\n",
    "\n",
    "def compare_dates(expected, actual):\n",
    "    \"\"\"Compares dates by parsing them into a standard format and ignoring time.\"\"\"\n",
    "    expected_date = parse_date(expected)\n",
    "    actual_date = parse_date_2(actual)\n",
    "    print(\"Expected data: \")\n",
    "    print(expected_date)\n",
    "    print(\"\\n Actual data: \")\n",
    "    print(actual_date)\n",
    "    if expected_date and actual_date:\n",
    "        return expected_date == actual_date\n",
    "    return False\n",
    "\n",
    "def evaluate_answers(data, threshold=0.75):\n",
    "    \"\"\"Evaluates the actual answers against the expected answers and displays results for each question.\"\"\"\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    print(\"Detailed Results:\\n\")\n",
    "    \n",
    "    for idx, item in enumerate(data):\n",
    "        expected_answer = str(item['expected_answer']).lower()\n",
    "        actual_answer = str(item['actual_answer']).lower()\n",
    "        correct = False\n",
    "        score = 0\n",
    "        \n",
    "        # Special case for description: Use token-based comparison\n",
    "        if \"description\" in item['question'].lower():\n",
    "            score = compare_textual_answers(preprocess_answer(expected_answer), preprocess_answer(actual_answer))\n",
    "            correct = score >= threshold\n",
    "        \n",
    "        # Special case for date: Use date parsing and comparison\n",
    "        elif \"date\" in item['question'].lower():\n",
    "            correct = compare_dates(expected_answer, actual_answer)\n",
    "            #score = 1.0 if correct else 0.0\n",
    "            if(correct):\n",
    "                score = 1.0\n",
    "            else:\n",
    "                correct = expected_answer in actual_answer\n",
    "                score = 1.0 if correct else 0.0\n",
    "        # For all other fields, check if the expected answer string is present in the actual answer\n",
    "        else:\n",
    "            correct = expected_answer in actual_answer\n",
    "            score = 1.0 if correct else 0.0\n",
    "        \n",
    "        y_true.append(1)  # Expected to match\n",
    "        y_pred.append(1 if correct else 0)\n",
    "        \n",
    "        # Display the result for this question\n",
    "        print(f\"Question {idx + 1}: {item['question']}\")\n",
    "        print(f\"Expected Answer: {item['expected_answer']}\")\n",
    "        print(f\"Actual Answer: {item['actual_answer']}\")\n",
    "        print(f\"Score: {score:.2f}\")\n",
    "        print(f\"Correct: {'Yes' if correct else 'No'}\\n\")\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "# Load the JSON file\n",
    "file_path = 'gpt_output_results.json'  # Replace with your JSON file path\n",
    "data = load_json(file_path)\n",
    "\n",
    "# Evaluate the answers and display detailed results\n",
    "precision, recall, f1 = evaluate_answers(data, threshold=0.75)\n",
    "\n",
    "# Print overall precision, recall, and F1 score\n",
    "print(\"Overall Results:\")\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Results:\n",
      "\n",
      "No date found in the sentence.\n",
      "Expected data: \n",
      "2016-05-11\n",
      "\n",
      " Actual data: \n",
      "None\n",
      "Question 1: What is the published date of CVE-2016-1044\n",
      "Expected Answer: 2016-05-11T10:59Z\n",
      "Actual Answer: According to the context, the published date of CVE-2016-1044 is:\n",
      "\n",
      "\"PublishedDate\": \"2016-05-11T10:59Z\"\n",
      "\n",
      "Data not available for anything else.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 2: What is the description of CVE-2016-1044\n",
      "Expected Answer: Adobe Reader and Acrobat before 11.0.16, Acrobat and Acrobat Reader DC Classic before 15.006.30172, and Acrobat and Acrobat Reader DC Continuous before 15.016.20039 on Windows and OS X allow attackers to bypass JavaScript API execution restrictions via unspecified vectors, a different vulnerability than CVE-2016-1038, CVE-2016-1039, CVE-2016-1040, CVE-2016-1041, CVE-2016-1042, CVE-2016-1062, and CVE-2016-1117.\n",
      "Actual Answer: The description of CVE-2016-1044 is:\n",
      "\n",
      "\"Adobe Reader and Acrobat before 11.0.16, Acrobat and Acrobat Reader DC Classic before 15.006.30172, and Acrobat and Acrobat Reader DC Continuous before 15.016.20039 on Windows and OS X allow attackers to bypass JavaScript API execution restrictions via unspecified vectors, a different vulnerability than CVE-2016-1038, CVE-2016-1039, CVE-2016-1040, CVE-2016-1041, CVE-2016-1042, CVE-2016-1062, and CVE-2016-1117.\"\n",
      "Score: 0.98\n",
      "Correct: Yes\n",
      "\n",
      "Question 3: What is the exploitability score of CVE-2016-1044\n",
      "Expected Answer: 3.9\n",
      "Actual Answer: The exploitability score for CVE-2016-1044 is 3.9.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 4: What is the impact score of CVE-2016-1044\n",
      "Expected Answer: 6.0\n",
      "Actual Answer: According to the provided context, the impact score of CVE-2016-1044 is 6.0.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 5: What is the base score of CVE-2016-1044\n",
      "Expected Answer: 10.0\n",
      "Actual Answer: The base score of CVE-2016-1044 is 10.0.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "No date found in the sentence.\n",
      "Expected data: \n",
      "2023-06-13\n",
      "\n",
      " Actual data: \n",
      "None\n",
      "Question 6: What is the published date of CVE-2023-2638\n",
      "Expected Answer: 2023-06-13T21:15Z\n",
      "Actual Answer: The published date of CVE-2023-2638 is 2023-06-13T21:15Z.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 7: What is the description of CVE-2023-2638\n",
      "Expected Answer: \n",
      "Rockwell Automation's FactoryTalk System Services does not verify that a backup configuration archive is password protected.\n",
      "\n",
      " \n",
      "\n",
      "Improper authorization in FTSSBackupRestore.exe may lead to the loading of malicious configuration archives.  This vulnerability may allow a local, authenticated non-admin user to craft a malicious backup archive, without password protection, that will be loaded by FactoryTalk System Services as a valid backup when a restore procedure takes places. User interaction is required for this vulnerability to be successfully exploited.\n",
      "\n",
      "\n",
      "\n",
      "Actual Answer: According to the context, the description of CVE-2023-2638 is:\n",
      "\n",
      "\"Rockwell Automation's FactoryTalk System Services does not verify that a backup configuration archive is password protected.\n",
      "Improper authorization in FTSSBackupRestore.exe may lead to the loading of malicious configuration archives. This vulnerability may allow a local, authenticated non-admin user to craft a malicious backup archive, without password protection, that will be loaded by FactoryTalk System Services as a valid backup when a restore procedure takes places. User interaction is required for this vulnerability to be successfully exploited.\"\n",
      "Score: 0.94\n",
      "Correct: Yes\n",
      "\n",
      "Question 8: What is the exploitability score of CVE-2023-2638\n",
      "Expected Answer: 1.3\n",
      "Actual Answer: The exploitability score of CVE-2023-2638 is 1.3.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 9: What is the impact score of CVE-2023-2638\n",
      "Expected Answer: 3.6\n",
      "Actual Answer: According to the context, the impact score of CVE-2023-2638 is:\n",
      "\n",
      "\"integrityImpact\": \"HIGH\",\n",
      "Score: 0.00\n",
      "Correct: No\n",
      "\n",
      "Question 10: What is the base score of CVE-2023-2638\n",
      "Expected Answer: 5.0\n",
      "Actual Answer: The base score of CVE-2023-2638 is 5.0.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "No date found in the sentence.\n",
      "Expected data: \n",
      "2015-06-30\n",
      "\n",
      " Actual data: \n",
      "None\n",
      "Question 11: What is the published date of CVE-2015-4226\n",
      "Expected Answer: 2015-06-30T15:59Z\n",
      "Actual Answer: The published date of CVE-2015-4226 is 2015-06-30T15:59Z.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 12: What is the description of CVE-2015-4226\n",
      "Expected Answer: The packet-storing feature on Cisco 9900 phones with firmware 9.3(2) does not properly support the RTP protocol, which allows remote attackers to cause a denial of service (device hang) by sending malformed RTP packets after a call is answered, aka Bug ID CSCur39976.\n",
      "Actual Answer: The description of CVE-2015-4226 is:\n",
      "\n",
      "\"The packet-storing feature on Cisco 9900 phones with firmware 9.3(2) does not properly support the RTP protocol, which allows remote attackers to cause a denial of service (device hang) by sending malformed RTP packets after a call is answered, aka Bug ID CSCur39976.\"\n",
      "Score: 0.91\n",
      "Correct: Yes\n",
      "\n",
      "Question 13: What is the exploitability score of CVE-2015-4226\n",
      "Expected Answer: 8.6\n",
      "Actual Answer: The exploitability score of CVE-2015-4226 is 8.6.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 14: What is the impact score of CVE-2015-4226\n",
      "Expected Answer: 6.9\n",
      "Actual Answer: The impact score of CVE-2015-4226 is 7.1, with a complete availability impact and no confidentiality or integrity impact.\n",
      "Score: 0.00\n",
      "Correct: No\n",
      "\n",
      "Question 15: What is the base score of CVE-2015-4226\n",
      "Expected Answer: 7.1\n",
      "Actual Answer: According to the context, the base score of CVE-2015-4226 is 7.1.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "No date found in the sentence.\n",
      "Expected data: \n",
      "2018-01-02\n",
      "\n",
      " Actual data: \n",
      "None\n",
      "Question 16: What is the published date of CVE-2017-17098\n",
      "Expected Answer: 2018-01-02T15:29Z\n",
      "Actual Answer: The published date for CVE-2017-17098 is: 2018-01-02T15:29Z.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 17: What is the description of CVE-2017-17098\n",
      "Expected Answer: The writeLog function in fn_common.php in gps-server.net GPS Tracking Software (self hosted) through 3.0 allows remote attackers to inject arbitrary PHP code via a crafted request that is mishandled during admin log viewing, as demonstrated by <?php system($_GET[cmd]); ?> in a login request.\n",
      "Actual Answer: The description of CVE-2017-17098 is:\n",
      "\n",
      "\"The writeLog function in fn_common.php in gps-server.net GPS Tracking Software (self hosted) through 3.0 allows remote attackers to inject arbitrary PHP code via a crafted request that is mishandled during admin log viewing, as demonstrated by <?php system($_GET[cmd]); ?> in a login request.\"\n",
      "Score: 0.92\n",
      "Correct: Yes\n",
      "\n",
      "Question 18: What is the exploitability score of CVE-2017-17098\n",
      "Expected Answer: 3.9\n",
      "Actual Answer: The exploitability score of CVE-2017-17098 is 3.9.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 19: What is the impact score of CVE-2017-17098\n",
      "Expected Answer: 5.9\n",
      "Actual Answer: According to the context, the impact score of CVE-2017-17098 is HIGH.\n",
      "Score: 0.00\n",
      "Correct: No\n",
      "\n",
      "Question 20: What is the base score of CVE-2017-17098\n",
      "Expected Answer: 9.8\n",
      "Actual Answer: According to the context, the CVE details for CVE-2017-17098 are:\n",
      "\n",
      "Base Score: 9.8\n",
      "Severity: CRITICAL\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "No date found in the sentence.\n",
      "Expected data: \n",
      "2005-12-20\n",
      "\n",
      " Actual data: \n",
      "None\n",
      "Question 21: What is the published date of CVE-2005-4366\n",
      "Expected Answer: 2005-12-20T01:03Z\n",
      "Actual Answer: The published date of CVE-2005-4366 is 2005-12-20T01:03Z.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 22: What is the description of CVE-2005-4366\n",
      "Expected Answer: Multiple SQL injection vulnerabilities in DRZES HMS 3.2 allow remote attackers to execute arbitrary SQL commands via the (1) plan_id parameter to (a) domains.php, (b) viewusage.php, (c) pop_accounts.php, (d) databases.php, (e) ftp_users.php, (f) crons.php, (g) pass_dirs.php, (h) zone_files.php, (i) htaccess.php, and (j) software.php; (2) the customerPlanID parameter to viewplan.php; (3) the ref_id parameter to referred_plans.php; (4) customerPlanID parameter to listcharges.php; and (5) the domain parameter to (k) pop_accounts.php, (d) databases.php, (e) ftp_users.php, (f) crons.php, (g) pass_dirs.php, (h) zone_files.php, (i) htaccess.php, and (j) software.php.  NOTE: the viewinvoice.php invoiceID vector is already covered by CVE-2005-4137.\n",
      "Actual Answer: The description of CVE-2005-4366 is:\n",
      "\n",
      "\"Multiple SQL injection vulnerabilities in DRZES HMS 3.2 allow remote attackers to execute arbitrary SQL commands via the (1) plan_id parameter to (a) domains.php, (b) viewusage.php, (c) pop_accounts.php, (d) databases.php, (e) ftp_users.php, (f) crons.php, (g) pass_dirs.php, (h) zone_files.php, (i) htaccess.php, and (j) software.php; (2) the customerPlanID parameter to viewplan.php; (3) the ref_id parameter to referred_plans.php; (4) customerPlanID parameter to listcharges.php; and (5) the domain parameter to (k) pop_accounts.php, (d) databases.php, (e) ftp_users.php, (f) crons.php, (g) pass_dirs.php, (h) zone_files.php, (i) htaccess.php, and (j) software.php.  NOTE: the viewinvoice.php invoiceID vector is already covered by CVE-2005-4137.\"\n",
      "Score: 0.99\n",
      "Correct: Yes\n",
      "\n",
      "Question 23: What is the exploitability score of CVE-2005-4366\n",
      "Expected Answer: 10.0\n",
      "Actual Answer: The exploitability score of CVE-2005-4366 is 10.0.\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Question 24: What is the impact score of CVE-2005-4366\n",
      "Expected Answer: 4.9\n",
      "Actual Answer: According to the provided context, the impact score for CVE-2005-4366 is:\n",
      "\n",
      "\"availabilityImpact\": \"NONE\",\\n\n",
      "\"integrityImpact\": \"PARTIAL\",\\n\n",
      "\"confidentialityImpact\": \"PARTIAL\"\n",
      "\n",
      "In summary, the impact of CVE-2005-4366 is partial on integrity and confidentiality, with no impact on availability.\n",
      "Score: 0.00\n",
      "Correct: No\n",
      "\n",
      "Question 25: What is the base score of CVE-2005-4366\n",
      "Expected Answer: 6.4\n",
      "Actual Answer: The original query asks for the base score of CVE-2005-4366, which is:\n",
      "\n",
      "\"baseScore\": 6.4\n",
      "Score: 1.00\n",
      "Correct: Yes\n",
      "\n",
      "Overall Results:\n",
      "Precision: 1.00\n",
      "Recall: 0.84\n",
      "F1 Score: 0.91\n"
     ]
    }
   ],
   "source": [
    "# in this date has been parsed into a common format to check it properly\n",
    "\n",
    "import json\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def load_json(file_path):\n",
    "    \"\"\"Loads the JSON file with questions, expected answers, and actual answers.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def preprocess_answer(answer):\n",
    "    \"\"\"Basic preprocessing to convert answers to lowercase and strip unnecessary characters.\"\"\"\n",
    "    return answer.lower().strip()\n",
    "\n",
    "def compare_textual_answers(expected, actual):\n",
    "    \"\"\"Token-based comparison for textual answers using cosine similarity (for descriptions).\"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([expected, actual])\n",
    "    similarity = cosine_similarity(vectors[0], vectors[1])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def parse_date(date_str):\n",
    "    \"\"\"Attempts to parse the date string into a standard format for comparison.\"\"\"\n",
    "    date_formats = [\n",
    "        \"%Y-%m-%dT%H:%MZ\", \"%Y-%m-%d\", \"%Y/%m/%d\", \"%Y-%m-%d %H:%M:%S\", \n",
    "        \"%B %d, %Y\", \"%b %d, %Y\"  # Adding long and short month formats (e.g., \"October 25, 2023\")\n",
    "    ]\n",
    "    for fmt in date_formats:\n",
    "        try:\n",
    "            #return datetime.strptime(date_str, fmt).date()  # Parse to date only\n",
    "            return datetime.strptime(date_str, fmt).strftime(\"%Y-%m-%d\")  # Parse to date only\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_date_2(date_str):\n",
    "\n",
    "    # Regular expression to match the date pattern\n",
    "    date_pattern = r\"([A-Za-z]+\\s\\d{1,2},\\s\\d{4})\"\n",
    "\n",
    "    # Find the date in the sentence\n",
    "    match = re.search(date_pattern, date_str)\n",
    "\n",
    "    # Check if a match is found\n",
    "    if match:\n",
    "        extracted_date = match.group(0)\n",
    "        # Convert the extracted date to a datetime object\n",
    "        try:\n",
    "            date_obj = datetime.strptime(extracted_date, \"%B %d, %Y\")\n",
    "            # Convert to ISO format\n",
    "            iso_date = date_obj.strftime(\"%Y-%m-%d\")\n",
    "            print(\"Extracted date in ISO format:\", iso_date)\n",
    "            return iso_date\n",
    "        except ValueError:\n",
    "            print(\"Date format is incorrect.\")\n",
    "    else:\n",
    "        print(\"No date found in the sentence.\")\n",
    "\n",
    "def compare_dates(expected, actual):\n",
    "    \"\"\"Compares dates by parsing them into a standard format and ignoring time.\"\"\"\n",
    "    expected_date = parse_date(expected)\n",
    "    actual_date = parse_date_2(actual)\n",
    "    print(\"Expected data: \")\n",
    "    print(expected_date)\n",
    "    print(\"\\n Actual data: \")\n",
    "    print(actual_date)\n",
    "    if expected_date and actual_date:\n",
    "        return expected_date == actual_date\n",
    "    return False\n",
    "\n",
    "def evaluate_answers(data, threshold=0.75):\n",
    "    \"\"\"Evaluates the actual answers against the expected answers and displays results for each question.\"\"\"\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    print(\"Detailed Results:\\n\")\n",
    "    \n",
    "    for idx, item in enumerate(data):\n",
    "        expected_answer = str(item['expected_answer']).lower()\n",
    "        actual_answer = str(item['actual_answer']).lower()\n",
    "        correct = False\n",
    "        score = 0\n",
    "        \n",
    "        # Special case for description: Use token-based comparison\n",
    "        if \"description\" in item['question'].lower():\n",
    "            score = compare_textual_answers(preprocess_answer(expected_answer), preprocess_answer(actual_answer))\n",
    "            correct = score >= threshold\n",
    "        \n",
    "        # Special case for date: Use date parsing and comparison\n",
    "        elif \"date\" in item['question'].lower():\n",
    "            correct = compare_dates(expected_answer, actual_answer)\n",
    "            #score = 1.0 if correct else 0.0\n",
    "            if(correct):\n",
    "                score = 1.0\n",
    "            else:\n",
    "                correct = expected_answer in actual_answer\n",
    "                score = 1.0 if correct else 0.0\n",
    "        \n",
    "        # For all other fields, check if the expected answer string is present in the actual answer\n",
    "        else:\n",
    "            correct = expected_answer in actual_answer\n",
    "            score = 1.0 if correct else 0.0\n",
    "        \n",
    "        y_true.append(1)  # Expected to match\n",
    "        y_pred.append(1 if correct else 0)\n",
    "        \n",
    "        # Display the result for this question\n",
    "        print(f\"Question {idx + 1}: {item['question']}\")\n",
    "        print(f\"Expected Answer: {item['expected_answer']}\")\n",
    "        print(f\"Actual Answer: {item['actual_answer']}\")\n",
    "        print(f\"Score: {score:.2f}\")\n",
    "        print(f\"Correct: {'Yes' if correct else 'No'}\\n\")\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "# Load the JSON file\n",
    "file_path = 'ollama_output_results_1.json'  # Replace with your JSON file path\n",
    "data = load_json(file_path)\n",
    "\n",
    "# Evaluate the answers and display detailed results\n",
    "precision, recall, f1 = evaluate_answers(data, threshold=0.75)\n",
    "\n",
    "# Print overall precision, recall, and F1 score\n",
    "print(\"Overall Results:\")\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy in /Users/shiv/Desktop/ChatNVD/env/lib/python3.12/site-packages (0.18.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.12 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install fuzzywuzzy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fuzzywuzzy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfuzzywuzzy\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfuzzywuzzy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fuzz\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_json\u001b[39m(file_path):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fuzzywuzzy'"
     ]
    }
   ],
   "source": [
    "# in this date has been parsed into a common format to check it properly\n",
    "\n",
    "import json\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datetime import datetime\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def load_json(file_path):\n",
    "    \"\"\"Loads the JSON file with questions, expected answers, and actual answers.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def preprocess_answer(answer):\n",
    "    \"\"\"Basic preprocessing to convert answers to lowercase and strip unnecessary characters.\"\"\"\n",
    "    return answer.lower().strip()\n",
    "\n",
    "def compare_textual_answers(expected, actual):\n",
    "    \"\"\"Token-based comparison for textual answers using cosine similarity (for descriptions).\"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([expected, actual])\n",
    "    similarity = cosine_similarity(vectors[0], vectors[1])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def parse_date(date_str):\n",
    "    \"\"\"Attempts to parse the date string into a standard format for comparison.\"\"\"\n",
    "    date_formats = [\n",
    "        \"%Y-%m-%dT%H:%MZ\", \"%Y-%m-%d\", \"%Y/%m/%d\", \"%Y-%m-%d %H:%M:%S\", \n",
    "        \"%B %d, %Y\", \"%b %d, %Y\"  # Adding long and short month formats (e.g., \"October 25, 2023\")\n",
    "    ]\n",
    "    for fmt in date_formats:\n",
    "        try:\n",
    "            #return datetime.strptime(date_str, fmt).date()  # Parse to date only\n",
    "            return datetime.strptime(date_str, fmt).strftime(\"%Y-%m-%d\")  # Parse to date only\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_date_2(date_str):\n",
    "\n",
    "    # Regular expression to match the date pattern\n",
    "    date_pattern = r\"([A-Za-z]+\\s\\d{1,2},\\s\\d{4})\"\n",
    "\n",
    "    # Find the date in the sentence\n",
    "    match = re.search(date_pattern, date_str)\n",
    "\n",
    "    # Check if a match is found\n",
    "    if match:\n",
    "        extracted_date = match.group(0)\n",
    "        # Convert the extracted date to a datetime object\n",
    "        try:\n",
    "            date_obj = datetime.strptime(extracted_date, \"%B %d, %Y\")\n",
    "            # Convert to ISO format\n",
    "            iso_date = date_obj.strftime(\"%Y-%m-%d\")\n",
    "            print(\"Extracted date in ISO format:\", iso_date)\n",
    "            return iso_date\n",
    "        except ValueError:\n",
    "            print(\"Date format is incorrect.\")\n",
    "    else:\n",
    "        print(\"No date found in the sentence.\")\n",
    "\n",
    "def compare_dates(expected, actual):\n",
    "    \"\"\"Compares dates by parsing them into a standard format and ignoring time.\"\"\"\n",
    "    expected_date = parse_date(expected)\n",
    "    actual_date = parse_date_2(actual)\n",
    "    print(\"Expected data: \")\n",
    "    print(expected_date)\n",
    "    print(\"\\n Actual data: \")\n",
    "    print(actual_date)\n",
    "    if expected_date and actual_date:\n",
    "        return expected_date == actual_date\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_answers(data, threshold=0.75):\n",
    "    \"\"\"Evaluates the actual answers against the expected answers and displays results for each question.\"\"\"\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    print(\"Detailed Results:\\n\")\n",
    "    \n",
    "    for idx, item in enumerate(data):\n",
    "        expected_answer = str(item['expected_answer']).lower()\n",
    "        actual_answer = str(item['actual_answer']).lower()\n",
    "        correct = False\n",
    "        score = 0\n",
    "        \n",
    "        # Special case for description: Use token-based comparison\n",
    "        if \"description\" in item['question'].lower():\n",
    "            score = compare_textual_answers(preprocess_answer(expected_answer), preprocess_answer(actual_answer))\n",
    "            correct = score >= threshold\n",
    "        \n",
    "        # Special case for date: Use date parsing and comparison\n",
    "        elif \"date\" in item['question'].lower():\n",
    "            correct = compare_dates(expected_answer, actual_answer)\n",
    "            if correct:\n",
    "                score = 1.0\n",
    "            else:\n",
    "                correct = expected_answer in actual_answer\n",
    "                score = 1.0 if correct else 0.0\n",
    "        \n",
    "        # Check if expected answer is \"no data found\" and if the actual answer contains similar phrases\n",
    "        elif expected_answer == \"no data found\":\n",
    "            # Define possible variations of \"no data found\"\n",
    "            no_data_variants = [\n",
    "                \"no data found\", \"data not found\", \"no data available\", \n",
    "                \"information not found\", \"data unavailable\", \"no information available\"\n",
    "            ]\n",
    "            \n",
    "            # Fuzzy matching threshold\n",
    "            fuzzy_threshold = 80  # Percentage similarity threshold for approximate matching\n",
    "            \n",
    "            # Check if any of the variations appear in the actual answer\n",
    "            for variant in no_data_variants:\n",
    "                if fuzz.partial_ratio(variant, actual_answer) >= fuzzy_threshold:\n",
    "                    correct = True\n",
    "                    score = 1.0\n",
    "                    break\n",
    "            else:\n",
    "                correct = False\n",
    "                score = 0.0\n",
    "        \n",
    "        # For all other fields, check if the expected answer string is present in the actual answer\n",
    "        else:\n",
    "            correct = expected_answer in actual_answer\n",
    "            score = 1.0 if correct else 0.0\n",
    "        \n",
    "        y_true.append(1)  # Expected to match\n",
    "        y_pred.append(1 if correct else 0)\n",
    "        \n",
    "        # Display the result for this question\n",
    "        print(f\"Question {idx + 1}: {item['question']}\")\n",
    "        print(f\"Expected Answer: {item['expected_answer']}\")\n",
    "        print(f\"Actual Answer: {item['actual_answer']}\")\n",
    "        print(f\"Score: {score:.2f}\")\n",
    "        print(f\"Correct: {'Yes' if correct else 'No'}\\n\")\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "# Load the JSON file\n",
    "file_path = 'ollama_output_results.json'  # Replace with your JSON file path\n",
    "data = load_json(file_path)\n",
    "\n",
    "# Evaluate the answers and display detailed results\n",
    "precision, recall, f1 = evaluate_answers(data, threshold=0.75)\n",
    "\n",
    "# Print overall precision, recall, and F1 score\n",
    "print(\"Overall Results:\")\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
